{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f7f95d-a538-42b9-b91e-96b6bf227844",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "import torch\n",
    "from d2l import torch as d2l\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.data as pyg_data\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data import HeteroData, Batch\n",
    "from torch_geometric.transforms import ToUndirected\n",
    "from torch_geometric.nn import GATConv, global_mean_pool, global_max_pool, global_add_pool\n",
    "from torch_geometric.nn import to_hetero\n",
    "import torch_geometric.transforms as T\n",
    "from torch.masked import MaskedTensor\n",
    "from functools import partial\n",
    "from IPython import display\n",
    "import torch.nn.utils.parametrizations as parametrizations  # 新的模块路径\n",
    "from torch.nn.utils import weight_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e99b2b-fda7-454f-8c71-af7cbce78590",
   "metadata": {},
   "source": [
    "<span style = 'color:red; font-size:25px'>MSE//RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b107c442-30ed-4e28-a8aa-3d04b7890c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mse(actual_values, predicted_values):\n",
    "    squared_errors = [(actual - predicted + 0.00115) ** 2 for actual, predicted in zip(actual_values, predicted_values)]\n",
    "    mse = sum(squared_errors) \n",
    "    return mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274d09cf-3588-4d69-ae0f-7d4197ee6695",
   "metadata": {},
   "source": [
    "<span style = 'color:red; font-size:25px'>ADE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572b5da0-4b98-4683-b858-e44f386feb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def utm_epsg_from_lonlat(lon_deg, lat_deg):\n",
    "    \"\"\"\n",
    "    根据经纬度选择合适的 UTM EPSG。\n",
    "    北半球: 326xx，南半球: 327xx\n",
    "    UTM zone = floor((lon + 180)/6) + 1\n",
    "    \"\"\"\n",
    "    zone = int(math.floor((lon_deg + 180.0) / 6.0) + 1)\n",
    "    if lat_deg >= 0:\n",
    "        return 32600 + zone\n",
    "    else:\n",
    "        return 32700 + zone\n",
    "\n",
    "def calculate_ade(predictions, ground_truth, mask, fixed_epsg = 32):\n",
    "    \"\"\"\n",
    "    用 UTM 将经纬度(°)转换为米，然后计算 ADE（米）。\n",
    "    predictions, ground_truth: (B, T, N, 2)  # [lon, lat] in degrees, WGS84\n",
    "    mask: (B, T, N, F) 或 (B, T, N, 1) 或 (B, T, N)\n",
    "    fixed_epsg:\n",
    "        - None: 自动按每条序列选择 UTM 分区（推荐）\n",
    "        - 例如 32632 或 32633：对整个批次强制使用单一投影（如你确认都在丹麦西/东）\n",
    "    choose_per_sequence:\n",
    "        - True: 每条序列用自己的 UTM 分区（根据该序列均值经纬度）\n",
    "        - False: 整个批次用同一个（若 fixed_epsg=None，则按整个批次均值选择）\n",
    "    返回：ADE（米）\n",
    "    \"\"\"\n",
    "    assert predictions.shape[-1] == 2 and ground_truth.shape[-1] == 2\n",
    "    device = predictions.device\n",
    "    dtype  = predictions.dtype\n",
    "\n",
    "    B, T, N, _ = predictions.shape\n",
    "\n",
    "    # 转到 CPU numpy 做投影（pyproj 在 numpy 上运行）\n",
    "    pred_np = predictions.detach().cpu().numpy()\n",
    "    gt_np   = ground_truth.detach().cpu().numpy()\n",
    "\n",
    "    # 结果容器（米坐标）\n",
    "    px = np.empty((B, T, N), dtype=np.float64)\n",
    "    py = np.empty((B, T, N), dtype=np.float64)\n",
    "    gx = np.empty((B, T, N), dtype=np.float64)\n",
    "    gy = np.empty((B, T, N), dtype=np.float64)\n",
    "\n",
    "    # 选择投影并转换\n",
    "    transformer = Transformer.from_crs(\"EPSG:4326\", f\"EPSG:{fixed_epsg}\", always_xy=True\n",
    "    lonp = pred_np[..., 0].reshape(-1); latp = pred_np[..., 1].reshape(-1)\n",
    "    xp, yp = transformer.transform(lonp, latp)\n",
    "    long = gt_np[..., 0].reshape(-1);  latg = gt_np[..., 1].reshape(-1)\n",
    "    xg, yg = transformer.transform(long, latg\n",
    "    px[:] = xp.reshape(B, T, N)\n",
    "    py[:] = yp.reshape(B, T, N)\n",
    "    gx[:] = xg.reshape(B, T, N)\n",
    "    gy[:] = yg.reshape(B, T, N\n",
    "                       \n",
    "    # 转回 torch\n",
    "    pred_m = torch.stack([torch.from_numpy(px), torch.from_numpy(py)], dim=-1).to(device=device, dtype=dtype)  # (B,T,N,2)\n",
    "    gt_m   = torch.stack([torch.from_numpy(gx), torch.from_numpy(gy)], dim=-1).to(device=device, dtype=dtype)\n",
    "\n",
    "    # 欧氏距离（米）\n",
    "    displacement_error = torch.linalg.norm(pred_m - gt_m, dim=-1)  # (B,T,N)\n",
    "\n",
    "    # 处理 mask 到 (B,T,N)\n",
    "    if mask.dim() == displacement_error.dim() + 1:\n",
    "        mask_reduced = mask.any(dim=-1).float()\n",
    "    elif mask.shape == displacement_error.shape:\n",
    "        mask_reduced = mask.float()\n",
    "    else:\n",
    "        mask_reduced = mask.squeeze(-1).float()\n",
    "\n",
    "    masked_error = displacement_error * mask_reduced\n",
    "    total_error  = masked_error.sum()\n",
    "    valid_count  = mask_reduced.sum().clamp_min(1)\n",
    "\n",
    "    ade = total_error / valid_count\n",
    "    return ade\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cca251-bbbd-4cfc-8aec-9832146c2e4e",
   "metadata": {},
   "source": [
    "<span style = 'color:red; font-size:25px'>数据提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbce680b-e5b7-499e-8a46-f127451d4f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(file_path, start_row, chunk_size):\n",
    "    \"\"\"\n",
    "    从 CSV 文件中逐批读取数据，将空值保留为空值。\n",
    "    \n",
    "    :param file_path: 文件路径\n",
    "    :param start_row: 起始行\n",
    "    :param chunk_size: 每次读取的行数\n",
    "    :return: 读取的 DataFrame\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data = pd.read_csv(file_path, header=None, skiprows=start_row, nrows=chunk_size, low_memory=False)\n",
    "        if len(data) < chunk_size:\n",
    "            print(f\"Data read is smaller than the expected chunk size ({chunk_size}).\")\n",
    "            return pd.DataFrame()  # 数据不足一个完整批次，返回空 DataFrame\n",
    "        return data.fillna(np.nan)  # 保留空值为 NaN\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(\"No more data to read. Exiting.\")\n",
    "        return pd.DataFrame()  # 捕获空数据错误，返回空 DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9eaef94-6263-4889-b555-a7d92fea2f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_data_generator(file_path, input_len, pred_len, batch_size):\n",
    "    \"\"\"\n",
    "    滑动窗口读取 CSV 文件并生成批次数据。\n",
    "    \"\"\"\n",
    "    total_len = input_len + pred_len\n",
    "    chunk_size = total_len + batch_size - 1  # 一个批次所需的总行数\n",
    "    start_row = 2  # 从第三行（索引为2）开始读取数据\n",
    "\n",
    "    while True:\n",
    "        # Step 1: 读取当前批次的数据\n",
    "        data = preprocess_data(file_path, start_row=start_row, chunk_size=chunk_size)\n",
    "        if data.empty:\n",
    "            # print(\"End of file or data insufficient for a full batch. Exiting.\")\n",
    "            break  # 数据不足或者文件末尾，直接退出\n",
    "\n",
    "        # Step 2: 选择数据的有效列（从第二列开始）\n",
    "        data = data.iloc[:, 1:]\n",
    "        data_values = data.values\n",
    "\n",
    "        # Step 3: 滑动窗口提取当前块的所有窗口数据\n",
    "        Data = []\n",
    "        for start_idx in range(0, len(data_values) - total_len + 1, 1):  # 步长为1\n",
    "            Data.append(data_values[start_idx: start_idx + total_len])\n",
    "\n",
    "        # Step 4: 如果提取不到有效窗口，直接结束\n",
    "        if not Data:\n",
    "            print(\"No valid data windows extracted. Exiting.\")\n",
    "            break\n",
    "\n",
    "        # Step 5: 返回当前批次的数据\n",
    "        yield Data\n",
    "\n",
    "        # Step 6: 更新起始行位置以读取下一块数据\n",
    "        start_row += chunk_size // 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bf10e4-ab35-4dbc-8ab3-a669248d7616",
   "metadata": {},
   "source": [
    "<span style = 'color:red; font-size:25px'>最大-最小化归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41088d7b-056b-4326-9ff0-aebafdbde9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_datat(out_Y, max_values, min_values):\n",
    "    \"\"\"\n",
    "    对形状为 (batch_size, 时间步, 节点数, 特征) 的张量进行最大最小归一化。\n",
    "\n",
    "    :param out_Y: 输入张量，形状为 (batch_size, 时间步, 节点数, 特征)\n",
    "    :param max_values: 每列特征的最大值张量，形状为 (特征,)\n",
    "    :param min_values: 每列特征的最小值张量，形状为 (特征,)\n",
    "    :return: \n",
    "        - normalized_data: 归一化后的张量，与输入 `out_Y` 的形状一致\n",
    "    \"\"\"\n",
    "    # 确保 max_values 和 min_values 是张量\n",
    "    max_values = torch.tensor(max_values, device=out_Y.device)\n",
    "    min_values = torch.tensor(min_values, device=out_Y.device)\n",
    "\n",
    "    # 检查维度\n",
    "    if max_values.dim() != 1 or min_values.dim() != 1:\n",
    "        raise ValueError(\"max_values 和 min_values 应该是一维张量，表示每个特征的最大和最小值\")\n",
    "\n",
    "    if max_values.size(0) != out_Y.size(-1):\n",
    "        raise ValueError(\"max_values 和 min_values 的大小应该与特征维度一致\")\n",
    "\n",
    "    # 执行归一化\n",
    "    normalized_data = (out_Y - min_values) / (max_values - min_values)\n",
    "\n",
    "    return normalized_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3de59f-b6c3-442b-9176-e7647ed10f6d",
   "metadata": {},
   "source": [
    "<span style = 'color:red; font-size:25px'>逆归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbab187e-e4e2-40aa-aeae-bef9cb41ce74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize_data(normalized_data, max_values, min_values):\n",
    "    \"\"\"\n",
    "    对三维数据的最后一个维度进行逆归一化。\n",
    "    \n",
    "    :param normalized_data: 形状为 (batch_size, num_points, num_features) 的归一化数据\n",
    "    :param max_values: 每列数据的最大值列表\n",
    "    :param min_values: 每列数据的最小值列表\n",
    "    :return: 逆归一化后的数据，形状与输入数据相同\n",
    "    \"\"\"\n",
    "    # 转换为 numpy 数组\n",
    "    normalized_data = np.array(normalized_data)\n",
    "    max_values = np.array(max_values)\n",
    "    min_values = np.array(min_values)\n",
    "    max_values = max_values[..., 0, 0]\n",
    "    min_values = min_values[..., 0, 0]\n",
    "    # 确保数据的最后一个维度与 max_values 和 min_values 一致\n",
    "    assert normalized_data.shape[-1] == max_values.shape[0], \"最后一个维度与最大最小值的长度不匹配\"\n",
    "    \n",
    "    # 逆归一化公式 x = normalized_data * (max - min) + min\n",
    "    denormalized_data = normalized_data * (max_values - min_values) + min_values\n",
    "    \n",
    "    return denormalized_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dea4fb9-6ff1-46a4-a19a-17d5f730a56c",
   "metadata": {},
   "source": [
    "<span style = 'color:red;font-size:25px'>计算半正弦距离"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63274d85-2abf-4448-bd66-97f885c3ae8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_distances(points, radius=6371):\n",
    "    \"\"\"\n",
    "    计算张量中各节点之间的半正弦距离，并将主对角线值设置为 1。\n",
    "    \n",
    "    参数:\n",
    "    points: 形状为 (N, 2) 的张量，其中每行是一个点的经纬度 [latitude, longitude]\n",
    "    radius: 地球半径，单位为千米，默认 6371\n",
    "    \n",
    "    返回:\n",
    "    distances: 形状为 (N, N) 的张量，表示两点之间的球面距离，单位为海里\n",
    "    \"\"\"\n",
    "    # 将经纬度从度转换为弧度\n",
    "    points_rad = points * torch.pi / 180.0  # 形状 (N, 2)\n",
    "    \n",
    "    # 提取纬度和经度\n",
    "    latitudes = points_rad[:, 0].unsqueeze(1)  # 形状 (N, 1)\n",
    "    longitudes = points_rad[:, 1].unsqueeze(1)  # 形状 (N, 1)\n",
    "    \n",
    "    # 计算两点之间的纬度和经度差\n",
    "    dlat = latitudes - latitudes.T  # 形状 (N, N)\n",
    "    dlon = longitudes - longitudes.T  # 形状 (N, N)\n",
    "    \n",
    "    # 使用半正矢公式计算 a\n",
    "    a = (torch.sin(dlat / 2) ** 2 +\n",
    "         torch.cos(latitudes) * torch.cos(latitudes.T) * torch.sin(dlon / 2) ** 2)\n",
    "    \n",
    "    # 计算 c 并返回距离矩阵\n",
    "    c = 2 * torch.arcsin(torch.sqrt(a))\n",
    "    distances_km = radius * c  # 将弧度距离转换为实际距离（千米）\n",
    "    \n",
    "    # 转换为海里单位\n",
    "    distances_nmi = distances_km / 1.852  # 1 海里 = 1.852 千米\n",
    "    \n",
    "    # 将主对角线设置为 1\n",
    "    distances_nmi.fill_diagonal_(1.0)\n",
    "    \n",
    "    return distances_nmi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0b7ac8-807c-4b66-8887-6d244260ea95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(F_data1, input_len, pred_len, statics_features):\n",
    "    total_len = input_len + pred_len  # 总时间窗口长度\n",
    "\n",
    "    batch_size = len(F_data1)\n",
    "    # if batch_size == 0:\n",
    "    #     return [], [], [], [], []\n",
    "        \n",
    "    sample_shape = np.array(F_data1[0]).shape\n",
    "    num_nodes = sample_shape[1] // 5  # 每五列为一个节点\n",
    "\n",
    "    # 将静态特征转为数组，加快后续索引\n",
    "    statics_list = np.array([statics_features[str(i)] for i in range(num_nodes)], dtype=float)\n",
    "    \n",
    "    # 输出初始化\n",
    "    F_p_all = []\n",
    "    input_X_all = []\n",
    "    output_Y_all = []\n",
    "    S_all = []\n",
    "    static_result_all = []\n",
    "    input_x_all = []\n",
    "    Static_result_all = []\n",
    "    # print('batch_size:', batch_size)\n",
    "    for i in range(batch_size):     # 提取每个批次的数据\n",
    "        F_data = np.array(F_data1[i])  # [时间步, num_nodes*5]\n",
    "        # 重塑为 [total_len, num_nodes, 5]\n",
    "        F_data_reshaped = F_data.reshape(total_len, num_nodes, 5)\n",
    "\n",
    "        # 判断整个窗口哪些节点完全有效（无NaN）\n",
    "        valid_node_mask = ~np.isnan(F_data_reshaped).any(axis=(0, 2))\n",
    "        f_p = np.where(valid_node_mask)[0].tolist()\n",
    "        F_p_all.append(f_p)  # 当前批次中的有效节点\n",
    " \n",
    "        # 分离输入和输出\n",
    "        in_x_reshaped = F_data_reshaped[:input_len]   # [input_len, num_nodes, 5]\n",
    "        out_y_reshaped = F_data_reshaped[input_len:]  # [pred_len, num_nodes, 5]\n",
    "\n",
    "        # 对输入数据进行非空值提取\n",
    "        valid_in_mask = ~np.isnan(in_x_reshaped).any(axis=2)\n",
    "\n",
    "        # 使用 np.where 一次性获取所有有效节点及对应时间步\n",
    "        all_valid_t, all_valid_nodes = np.where(valid_in_mask)  # 寻找有效节点对应的时间步和节点索引\n",
    "        # 提取对应的特征\n",
    "        non_empty_features_all = in_x_reshaped[all_valid_t, all_valid_nodes, :]   # 提取该批次中的索引\n",
    "        # 提取对应的静态特征\n",
    "        sta_result_all_nodes = statics_list[all_valid_nodes]   # 提取静态特征\n",
    "\n",
    "        # 根据时间步对数据进行分组\n",
    "        # np.unique 返回unique的时间步，以及对应出现次数\n",
    "        unique_t, counts = np.unique(all_valid_t, return_counts=True)\n",
    "\n",
    "        # 按照每个时间步的有效节点数进行分割\n",
    "        split_indices = np.split(np.arange(len(all_valid_t)), np.cumsum(counts[:-1]))\n",
    "\n",
    "        # 还原为每个时间步对应的数据列表\n",
    "        input_X = [non_empty_features_all[idx] for idx in split_indices]\n",
    "        S = [all_valid_nodes[idx] for idx in split_indices]\n",
    "        static_result = [sta_result_all_nodes[idx] for idx in split_indices]\n",
    "\n",
    "        input_X_all.append(input_X)\n",
    "        S_all.append(S)\n",
    "        static_result_all.append(static_result)\n",
    "\n",
    "        # 构建预测数据 output_Y\n",
    "        if not f_p: \n",
    "            output_y = np.array([])\n",
    "            input_x0 = np.array([])\n",
    "            statics_list0 = np.array([])\n",
    "        else:\n",
    "            output_y = out_y_reshaped[:, f_p, :]  # [pred_len, len(f_p), 5]\n",
    "            input_x0 = in_x_reshaped[:, f_p, :]\n",
    "            Statics_list0 = statics_list[f_p, :]\n",
    "            statics_list0 = np.repeat(Statics_list0[np.newaxis, :, :], input_x0.shape[0], axis=0)\n",
    "        output_Y_all.append(output_y)\n",
    "        input_x_all.append(input_x0)\n",
    "        Static_result_all.append(statics_list0)\n",
    "        \n",
    "    return input_X_all, F_p_all, output_Y_all, S_all, static_result_all, input_x_all, Static_result_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a1cea3-3503-40a6-bd72-7153766d220a",
   "metadata": {},
   "source": [
    "<span style = 'color:red;font-size:25px'>提取静态信息(返回为一个字典)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d046f334-22a5-48d3-ade6-a13caf24324f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mmsi_features(file_path):\n",
    "    \"\"\"\n",
    "    提取文件中 MMSI 号及其对应特征值，并将字典键改为顺序索引。\n",
    "    \n",
    "    :param file_path: 文件路径\n",
    "    :return: 字典，其中键为顺序索引（从 1 开始），值为特征值列表\n",
    "    \"\"\"\n",
    "    # 读取数据\n",
    "    data = pd.read_csv(file_path, header=None)\n",
    "    \n",
    "    # 第一行（索引为0）为MMSI号\n",
    "    mmsi_row = data.iloc[0]\n",
    "    \n",
    "    # 第三行（索引为2）为特征值\n",
    "    feature_row = data.iloc[2]\n",
    "    \n",
    "    # 字典存储结果\n",
    "    mmsi_features = {}\n",
    "    \n",
    "    # 遍历MMSI号及其对应的特征值\n",
    "    for col_idx, mmsi in enumerate(mmsi_row):\n",
    "        if pd.notna(mmsi):  # 跳过空值\n",
    "            if mmsi not in mmsi_features:\n",
    "                mmsi_features[mmsi] = []\n",
    "            mmsi_features[mmsi].append(feature_row[col_idx])\n",
    "    \n",
    "    # 替换键为索引\n",
    "    indexed_features = {}\n",
    "    for index, (key, value) in enumerate(mmsi_features.items(), start=0):\n",
    "        indexed_features[str(index)] = value  # 转为字符串形式的索引\n",
    "    \n",
    "    return indexed_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d98b14-94ec-4d1a-a157-a679007175ba",
   "metadata": {},
   "source": [
    "<span style = 'color:red;font-size:25px'>将onehot编码转换成索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06311923-e3ee-4535-a3d6-5469ba60856e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_to_index(one_hot_str):\n",
    "    \"\"\"\n",
    "    将 one-hot 编码字符串解析为索引。\n",
    "    \"\"\"\n",
    "    one_hot_list = list(map(int, one_hot_str.split(',')))\n",
    "    return one_hot_list.index(1)\n",
    "\n",
    "def transform_data(data_dict):\n",
    "    \"\"\"\n",
    "    将字典数据转换为新的格式，用索引替代 one-hot 编码。\n",
    "    \"\"\"\n",
    "    transformed_data = {}\n",
    "    for key, value in data_dict.items():\n",
    "        \n",
    "        # 提取 one-hot 编码并转为索引\n",
    "        index = one_hot_to_index(value[0])\n",
    "        \n",
    "        # 替换原始 one-hot 编码为索引值，保持字典格式\n",
    "        transformed_data[key] = [index] + value[1:]\n",
    "    return transformed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff4c454-ef95-4cb3-accd-89c7bec46cb9",
   "metadata": {},
   "source": [
    "# <span style = 'color:red;font-size:25px'>提取静态数据特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2488d5d0-8ef8-4b42-92a9-366837553fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sfeatures(S, features_dict):\n",
    "    \"\"\"\n",
    "    根据列表 S 中的节点 ID 提取对应的特征，并将特征值转换为浮点型。\n",
    "    \n",
    "    :param S: 一个列表，其中每个元素是一个包含节点 ID 的数组。\n",
    "    :param features_dict: 一个字典，键为节点 ID，值为对应的特征列表。\n",
    "    :return: 一个列表，每个时间点下的节点特征列表，特征值为浮点型。\n",
    "    \"\"\"\n",
    "    result = []\n",
    "\n",
    "    for node_ids in S:\n",
    "        # 提取每个时间点的节点特征并转换为浮点型\n",
    "        node_features = [\n",
    "            [float(value) for value in features_dict.get(str(node_id), [])] \n",
    "            for node_id in node_ids\n",
    "        ]\n",
    "        result.append(node_features)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92670b46-11e3-4060-a17c-445d179fd12d",
   "metadata": {},
   "source": [
    "<span style = 'color:red;font-size:25px'>转换成onehot编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747605a2-c79e-4bed-a1b8-b72bde65ea0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_onehot(data, device, onehot_length = 20):\n",
    "    \"\"\"\n",
    "    将输入二维张量的第一个特征转换为 one-hot 编码，并与其他特征拼接。\n",
    "    \n",
    "    :param data: 输入二维张量，形状为 [N, F]，其中 N 是节点数，F 是特征数。\n",
    "    :param onehot_length: one-hot 编码的长度。\n",
    "    :return: 转换后的张量，形状为 [N, onehot_length + F - 1]。\n",
    "    \"\"\"\n",
    "    # 提取第一个特征索引并转换为整型\n",
    "    indices = data[:, 0].long()\n",
    "    \n",
    "    # 创建 one-hot 编码张量\n",
    "    onehot = torch.zeros(data.size(0), onehot_length, dtype=torch.float32, device = device)  # [N, onehot_length]\n",
    "    onehot.scatter_(1, indices.unsqueeze(1), 1)  # 在指定位置设置为 1\n",
    "    \n",
    "    return onehot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2d60c1-a3d9-447e-8f9e-8126841b2150",
   "metadata": {},
   "source": [
    "<span style = 'color:red;font-size:25px'>异构图卷积"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356b5197-794b-4a02-b2f9-b125554e412b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Spatial_GATD(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, gat_heads):\n",
    "        super(Spatial_GATD, self).__init__()\n",
    "        # 第一层 GAT: 输入特征 16, 输出特征 8, 注意力头数 32\n",
    "        self.gat1 = GATConv(input_dim, hidden_dim, heads=gat_heads, concat=True, add_self_loops=False)\n",
    "        # 第二层 GAT: 输入特征 32*8=256 (由第一层输出计算)，输出特征 16，注意力头数 1\n",
    "        self.gat2 = GATConv(hidden_dim * gat_heads, input_dim, heads=1, concat=True, add_self_loops=False)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "\n",
    "        # 第一层 GAT\n",
    "        x = self.gat1(x, edge_index, edge_attr = edge_attr)  # 输出形状 (节点数, 256)\n",
    "\n",
    "        x = F.elu(x)\n",
    "\n",
    "        # 第二层 GAT\n",
    "        x = self.gat2(x, edge_index, edge_attr = edge_attr)  # 输出形状 (节点数, 16)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1a411d-ef9d-4025-9788-86712370b4a1",
   "metadata": {},
   "source": [
    "<span style = 'color:red;font-size:20px'>异构图计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747dca88-8cdd-47ce-a1da-e3114f456804",
   "metadata": {},
   "outputs": [],
   "source": [
    "class H_Model(torch.nn.Module):\n",
    "    def __init__(self, hidden_dimS, num_heads, embedding_dim2):\n",
    "        super(H_Model, self).__init__()\n",
    "        \n",
    "        # 异构图卷积\n",
    "        self.gatD = Spatial_GATD(hidden_dimS, hidden_dimS, num_heads)\n",
    "\n",
    "        metadataD = (\n",
    "                          ['DYA', 'STA'],  # 节点类型\n",
    "                          [\n",
    "                              ('DYA', 'DD', 'DYA'),    # 从 DYA 到 DYA 的边类型 DD\n",
    "                              ('DYA', 'DS', 'STA'),    # 从 DYA 到 STA 的边类型 DS\n",
    "                              ('STA', 'rev_DS', 'DYA'), # 从 STA 到 DYA 的边类型 rev_DS\n",
    "                              ('STA', 'SS', 'STA')    # 从 STA 到 STA 的边类型 DD\n",
    "                          ]\n",
    "                    )\n",
    "        \n",
    "        self.gatD = to_hetero(self.gatD, metadata=metadataD)\n",
    "\n",
    "    def forward(self, xd_dict, data_D):\n",
    "        edge_indexD = data_D.edge_index_dict\n",
    "        edge_attrD = data_D.edge_attr_dict\n",
    "        x_dictd = self.gatD(xd_dict, edge_indexD, edge_attrD)\n",
    "        \n",
    "        return x_dictd['DYA'], x_dictd['STA']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4faa475-b37c-41b8-9912-adee63ef2771",
   "metadata": {},
   "source": [
    "<span style = 'color:red;font-size:25px'>构建异构图数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0d55be-4b96-49f6-ac84-de923bf58cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def HeteroGraphBuilder_batch(dynamic_tensor, static_tensor, masks, device, distances):\n",
    "    \"\"\"\n",
    "    构建异构图数据和同构图数据，输入为 (batch_size, time_steps, num_nodes, feature_dim)\n",
    "    动态节点和静态节点的数量相同，特征维度不同\n",
    "    并生成对应的 batch 向量\n",
    "    同时增加动态节点的同构图数据构造\n",
    "    :param dynamic_tensor: 动态节点特征张量 (batch_size, time_steps, num_nodes, dynamic_feat_dim)\n",
    "    :param static_tensor: 静态节点特征张量 (batch_size, time_steps, num_nodes, static_feat_dim)\n",
    "    :param masks: 掩码张量 (batch_size, time_steps, num_nodes)，值为0表示需要删除的节点\n",
    "    :param device: 设备\n",
    "    :return: dataD (HeteroData), batch (Tensor)\n",
    "    \"\"\"    \n",
    "    B, T, N, F_d = dynamic_tensor.shape\n",
    "    _, _, _, F_s = static_tensor.shape\n",
    "    \n",
    "    dynamic_tensor = dynamic_tensor.to(device)\n",
    "    static_tensor = static_tensor.to(device)\n",
    "    masks = masks.to(device)\n",
    "    \n",
    "    total_subgraphs = B * T  # 总子图数量\n",
    "    total_nodes = B * T * N\n",
    "\n",
    "    # 动态节点和静态节点的全局特征展开\n",
    "    X_D_global = dynamic_tensor.reshape(total_subgraphs * N, F_d)     # 形状为(batch_size * time_steps * num_nodes, feature_dim)\n",
    "    X_S_global = static_tensor.reshape(total_subgraphs * N, F_s)      # 形状为(batch_size * time_steps * num_nodes, feature_dim)\n",
    "\n",
    "    # 生成 batch 向量\n",
    "    batch_vector = torch.repeat_interleave(torch.arange(total_subgraphs, device=device), N)\n",
    "\n",
    "    # 单个子图的节点编号\n",
    "    node_ids_local = torch.arange(N, dtype=torch.long, device=device)\n",
    "\n",
    "    # 单个子图的边索引（动态节点和静态节点复用相同的逻辑）, 单连接\n",
    "    if N > 1:\n",
    "        edges_local = torch.combinations(node_ids_local.cpu(), r=2, with_replacement=False).T.to(device)   # 使节点间相互连接\n",
    "    else:\n",
    "        edges_local = torch.empty((2, 0), dtype=torch.long, device=device)\n",
    "    self_loops = torch.stack([node_ids_local, node_ids_local], dim=0)\n",
    "    edges_local = torch.cat([edges_local, self_loops], dim=1)  # (2, num_edges)\n",
    "    # 计算全局偏移\n",
    "    offsets = torch.arange(total_subgraphs, device=device) * N   # 每张图的起始节点\n",
    "    \n",
    "    # 生成所有可能的边（包括自连接）\n",
    "    cross_edges_local = torch.cartesian_prod(node_ids_local, node_ids_local).T.to(device)  # (2, N*N)\n",
    "    \n",
    "    # 去除自连接边\n",
    "    mask = cross_edges_local[0] != cross_edges_local[1]\n",
    "    cross_edges_local = cross_edges_local[:, mask]  # (2, N*(N-1))\n",
    "    \n",
    "    # 展平 offsets\n",
    "    offsets_flattened = offsets.flatten()\n",
    "    \n",
    "    # 将局部边索引扩展到所有子图\n",
    "    cross_edges_expanded = (\n",
    "        cross_edges_local.unsqueeze(1) + offsets_flattened.unsqueeze(0).unsqueeze(-1)\n",
    "    ).reshape(2, -1)  # 最终形状: (2, total_subgraphs * N * (N-1))\n",
    "\n",
    "\n",
    "    # 将单张图的结构扩展到所有子图\n",
    "    edges_expanded = (edges_local.unsqueeze(1) + offsets.unsqueeze(0).unsqueeze(-1)).reshape(2, -1)   # 生成全局(相同节点)边\n",
    "\n",
    "    # 构建 HeteroData 对象\n",
    "    dataD = HeteroData()\n",
    "    \n",
    "    # 动态节点\n",
    "    dataD['DYA'].x = X_D_global\n",
    "    dataD['DYA', 'DD', 'DYA'].edge_index = edges_expanded\n",
    "    # 静态节点\n",
    "    dataD['STA'].x = X_S_global\n",
    "    # 动态与静态的边\n",
    "    dataD['DYA', 'DS', 'STA'].edge_index = cross_edges_expanded\n",
    "\n",
    "    # 边连接矩阵\n",
    "    edgeD_DD = dataD['DYA', 'DD', 'DYA'].edge_index  # 双向边\n",
    "    edgeD_DS = dataD['DYA', 'DS', 'STA'].edge_index  # 单向边\n",
    "\n",
    "    # 找出填充点的位置(即值为0的位置)，只会严格遵守最初定义的节点ID，并不会改变节点ID\n",
    "    # 展平成一维张量\n",
    "    flattened_tensor = masks.flatten()\n",
    "    # 找出值为0的位置即要删除的点\n",
    "    zero_indices = (flattened_tensor == 0).nonzero(as_tuple=False).squeeze()\n",
    "    # 使用布尔掩码删除指定位置的值\n",
    "    Mask = torch.ones(batch_vector.size(0), dtype=torch.bool, device=device)\n",
    "    Mask[zero_indices] = False  # 将需要删除的位置标记为 False\n",
    "    batch = batch_vector[Mask]\n",
    "\n",
    "    # 动态节点的边过滤\n",
    "    # 判断边的起点或终点是否在节点编号列表中\n",
    "    maskD_DD = ~(\n",
    "        torch.isin(edgeD_DD[0], zero_indices) |\n",
    "        torch.isin(edgeD_DD[1], zero_indices)\n",
    "    )\n",
    "    # print('maskD_DD:',maskD_DD)\n",
    "    maskD_DS = ~(\n",
    "        torch.isin(edgeD_DS[0], zero_indices) |\n",
    "        torch.isin(edgeD_DS[1], zero_indices)\n",
    "    )\n",
    "   \n",
    "    # 删除无用节点，重新赋予边连接\n",
    "    edgeD_DD = edgeD_DD[:, maskD_DD]\n",
    "    edgeD_DS = edgeD_DS[:, maskD_DS]\n",
    "  \n",
    "    # 重新映射边索引\n",
    "    dataD['DYA', 'DD', 'DYA'].edge_index = edgeD_DD\n",
    "    dataD['DYA', 'DS', 'STA'].edge_index = edgeD_DS\n",
    "    dataD['STA', 'SS', 'STA'].edge_index = edgeD_DD\n",
    "\n",
    "    # 赋予边特征值\n",
    "    adj_DD = distances[edgeD_DD[0], edgeD_DD[1]]\n",
    "    adj_DS = distances[edgeD_DS[0], edgeD_DS[1]]\n",
    "    dataD['DYA', 'DD', 'DYA'].edge_attr = adj_DD\n",
    "    dataD['DYA', 'DS', 'STA'].edge_attr = adj_DS\n",
    "    dataD['STA', 'SS', 'STA'].edge_attr = adj_DD\n",
    "    \n",
    "    # 转换为无向图\n",
    "    dataD = ToUndirected()(dataD)\n",
    "\n",
    "    return dataD, batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302d7b93-a19d-48c9-814e-e41a936fecad",
   "metadata": {},
   "source": [
    "<span style = 'color:red;font-size:25px'>获取适合于TCN输入的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1925c5-2b90-4950-ad9c-cef7bf172d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tensor_and_extract_features(tensor, batch_size, input_len, masks, device):\n",
    "    \"\"\"\n",
    "    将输入张量按照batch值划分为多个时间步，并根据F中的索引提取每个时间步的特征。\n",
    "    :param tensor: 输入张量，形状为 (batch_size, 时间步数, 节点总数, 特征维度)\n",
    "    :param masks: 形状为 (batch_size, 时间步数, 节点总数)\n",
    "    :param batch: 对应的batch值，形状为 (节点总数, )\n",
    "    :param F: 用于轨迹预测的节点在原完整数据中的索引列表形状为(batch_size, 节点ID)\n",
    "    :param S: 每个时间步的节点在原数据中的索引列表（numpy数组组成的列表）(batch_size, 时间数, 节点ID)\n",
    "    :return: 三维张量，形状为 (时间步数, 节点数, 特征维度)\n",
    "    \"\"\"\n",
    "\n",
    "    # tensor = tensor.reshape(batch_size, input_len, -1, tensor.shape[-1]) # 形状为(B, T, N, F)\n",
    "    # 1) 逐 batch 提取 num_nodes 的真实数据\n",
    "    result_list = []\n",
    "    \n",
    "    for b in range(batch_size):\n",
    "        # 当前 batch 的遮掩矩阵 (T, N)\n",
    "        mask_b = masks[b]  # shape: (T, N)\n",
    "        \n",
    "        # 转置掩码以适配 X 的最后两维 (N, T)\n",
    "        valid_nodes = mask_b.any(dim=0)  # shape: (N,) -> 是否有非填充数据\n",
    "        valid_node_indices = torch.where(valid_nodes)[0]  # 有效节点索引\n",
    "    \n",
    "        # 提取 X 中有效的节点数据\n",
    "        tensor_valid = tensor[b, :, valid_node_indices, :]  # shape: (T, num_valid_nodes, F)\n",
    "        result_list.append(tensor_valid)\n",
    "    \n",
    "    # 2) 拼接结果并重新排列为目标形状\n",
    "    final_result = torch.cat(result_list, dim=1).permute(1, 0, 2).to(device) # shape: (B * N, T, F)\n",
    "    final_result = final_result.permute(0, 2, 1) # shape: (B * N, F, T)\n",
    "    \n",
    "    # 返回形状(batch_size * 节点数, 特征维度, 1, 时间步数)\n",
    "    return final_result.reshape(final_result.shape[0], final_result.shape[1], 1, final_result.shape[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e0df19-78b2-496e-8fc9-cd8553562c1d",
   "metadata": {},
   "source": [
    "<span style = 'color:red;font-size:25px'>LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a4ff94-cc7b-42d2-987e-4ce0e921053b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, bidirectional=False, dropout=0.0):\n",
    "        super(LSTMNetwork, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.bidirectional = bidirectional\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=input_size,\n",
    "                            hidden_size=hidden_size,\n",
    "                            num_layers=num_layers,\n",
    "                            batch_first=True,\n",
    "                            bidirectional=bidirectional,\n",
    "                            dropout=dropout if num_layers > 1 else 0.0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        前向传播方法。\n",
    "\n",
    "        参数:\n",
    "            x (Tensor): 输入张量，形状为 (batch_size, seq_length, input_size)。\n",
    "\n",
    "        返回:\n",
    "            output (Tensor): 每个时间步最后一层的隐藏状态，形状为 \n",
    "                             (batch_size, seq_length, hidden_size * num_directions)。\n",
    "        \"\"\"\n",
    "        output, (h_n, c_n) = self.lstm(x)\n",
    "        \n",
    "        return output, h_n, c_n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1f74d8-06fa-42e8-8522-4f38beebb45b",
   "metadata": {},
   "source": [
    "<span style = 'color:red;font-size:20px'>平均池化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61908f5a-bff5-4af2-9abf-0b43abedc697",
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_average_pooling(x, mask, pool_dim, device):\n",
    "    \"\"\"\n",
    "    x: 输入张量，形状为 (batch_size, feature_dim, num_nodes, time_steps)\n",
    "    mask: 掩码张量，形状为 (batch_size, time_steps, num_nodes)\n",
    "    pool_dim: 池化维度，0 -> num_nodes，1 -> time_steps，2 -> feature_dim\n",
    "    返回: 平均池化后的张量\n",
    "    \"\"\"\n",
    "    x = x.to(device)\n",
    "    mask = mask.to(device)\n",
    "    # 调整掩码形状以匹配 x \n",
    "    mask = mask.unsqueeze(1)  # 形状变为 (batch_size, 1, time_steps, num_nodes)\n",
    "    mask = mask.permute(0, 1, 3, 2)  # 调整为 (batch_size, 1, num_nodes, time_steps)\n",
    "    \n",
    "    # 确保 mask 的 dtype 与 x 相同\n",
    "    mask = mask.type_as(x)\n",
    "    \n",
    "    # 应用掩码 \n",
    "    x_masked = x * mask  # 填充部分被置为 0\n",
    "    \n",
    "    # 计算有效元素的数量\n",
    "    mask_sum = mask.sum(dim=2)  # 在 num_nodes 维度上求和，形状为 (batch_size, feature_dim, time_steps)\n",
    "    mask_sum = mask_sum.clamp(min=1e-6)  # 防止除以零\n",
    "    \n",
    "    # 对不同维度进行池化\n",
    "    if pool_dim == 2:  # 沿着 num_nodes 维度池化\n",
    "        x_sum = x_masked.sum(dim=2)  # 在 num_nodes 维度上求和\n",
    "        x_avg = x_sum / mask_sum\n",
    "        # print('x_avg2:',x_avg)\n",
    "    elif pool_dim == 3:  # 沿着 time_steps 维度池化\n",
    "        x_sum = x_masked.sum(dim=3)  # 在 time_steps 维度上求和\n",
    "        mask_sum = mask.sum(dim=3)  # 计算有效元素数量\n",
    "        x_avg = x_sum / mask_sum.clamp(min=1e-6)\n",
    "        # print('x_avg3:',x_avg)\n",
    "    elif pool_dim == 1:  # 沿着 feature_dim 维度池化\n",
    "        # 扩展 mask 使其与 x 形状一致 (batch_size, feature_dim, num_nodes, time_steps)\n",
    "        mask_expanded = mask.expand(-1, x.size(1), -1, -1)  # 扩展为 (batch_size, feature_dim, num_nodes, time_steps)\n",
    "        \n",
    "        # 计算有效元素的数量，沿着 feature_dim 维度进行求和\n",
    "        mask_sum = mask_expanded.sum(dim=1)  # 在 feature_dim 维度上求和\n",
    "        mask_sum = mask_sum.clamp(min=1e-6)  # 防止除以零\n",
    "        x_sum = x_masked.sum(dim=1)  # 在 feature_dim 维度上求和\n",
    "        x_avg = x_sum / mask_sum\n",
    "    return x_avg  # 返回(batch_size, feature_dim, num_nodes, time_steps)消除特定维度"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6031276b-96c4-4060-9033-474242169279",
   "metadata": {},
   "source": [
    "<span style = 'color:red;font-size:20px'>最大池化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bad00ff-2b33-44b0-91f4-fdb8b7336aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_max_pooling(x, mask, pool_dim, device):\n",
    "    \"\"\"\n",
    "    x: 输入张量，形状为 (batch_size, feature_dim, num_nodes, time_steps)\n",
    "    mask: 掩码张量，形状为 (batch_size, time_steps, num_nodes)\n",
    "    pool_dim: 池化维度，0 -> num_nodes，1 -> time_steps，2 -> feature_dim\n",
    "    返回: 最大池化后的张量\n",
    "    \"\"\"\n",
    "    # 调整掩码形状以匹配 x\n",
    "    mask = mask.unsqueeze(1)  # 形状变为 (batch_size, 1, time_steps, num_nodes)\n",
    "    mask = mask.permute(0, 1, 3, 2)  # 调整为 (batch_size, 1, num_nodes, time_steps)\n",
    "    mask = mask.to(device)\n",
    "    x = x.to(device)\n",
    "    # 将填充部分设置为 -inf\n",
    "    x_masked = x.masked_fill(mask == 0, float('-inf'))\n",
    "    \n",
    "    # 对不同维度进行池化\n",
    "    if pool_dim == 2:  # 沿着 num_nodes 维度池化\n",
    "        x_max, _ = x_masked.max(dim=2)  # 在 num_nodes 维度上取最大值\n",
    "        # 填充部分的值保留为 -inf（即填充）\n",
    "        x_max = x_max.masked_fill(mask.sum(dim=2) == 0, 0)\n",
    "\n",
    "    elif pool_dim == 3:  # 沿着 time_steps 维度池化\n",
    "        x_max, _ = x_masked.max(dim=3)  # 在 time_steps 维度上取最大值\n",
    "        \n",
    "        # 填充部分的值保留为 -inf（即填充）\n",
    "        x_max = x_max.masked_fill(mask.sum(dim=3) == 0, 0)\n",
    "        \n",
    "    elif pool_dim == 1:  # 沿着 feature_dim 维度池化\n",
    "        x_max, _ = x_masked.max(dim=1)  # 在 feature_dim 维度上取最大值\n",
    "        # 填充部分的值保留为 -inf（即填充）\n",
    "        x_max = x_max.masked_fill(mask.sum(dim=1) == 0, 0)\n",
    "\n",
    "    return x_max  # 返回(batch_size, feature_dim, num_nodes, time_steps)消除特定维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab66767-34ce-4e40-af99-0a2a7b548e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionModule(nn.Module):\n",
    "    def __init__(self, kernel_size, pool_dim1, pool_dim2, input_channels = 1):\n",
    "        super(AttentionModule, self).__init__()\n",
    "        self.pool_dim1 = pool_dim1\n",
    "        self.pool_dim2 = pool_dim2\n",
    "\n",
    "        # Nodes 和 Time交互\n",
    "        self.nt_conv = nn.Sequential(\n",
    "            nn.Conv2d(2, 1, kernel_size=kernel_size, padding = (kernel_size - 1) // 2),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.ReLU(),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # Feature和 Nodes交互\n",
    "        self.fn_conv = nn.Sequential(\n",
    "            nn.Conv2d(2 * input_channels, input_channels, kernel_size=kernel_size, padding = (kernel_size - 1) // 2),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.ReLU(),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, mask, device):\n",
    "        \"\"\"\n",
    "        x: 输入张量，形状为 (batch_size, feature_dim, num_nodes, time_steps)\n",
    "        mask: 掩码张量，形状为 (batch_size, time_steps, num_nodes)\n",
    "        pool_dim: 池化维度，0 -> num_nodes，1 -> time_steps，2 -> feature_dim\n",
    "        返回: 最大池化后的张量\n",
    "        \"\"\"\n",
    "        # nodes - time_steps\n",
    "        avg_nt = masked_average_pooling(x, mask, self.pool_dim1, device)\n",
    "        max_nt = masked_max_pooling(x, mask, self.pool_dim1, device)\n",
    "        avg_nt = avg_nt.unsqueeze(1)\n",
    "        max_nt = max_nt.unsqueeze(1)\n",
    "        am_nt = torch.cat((avg_nt, max_nt), dim = 1)\n",
    "        att_nt = self.nt_conv(am_nt) # 输出形状为(batch_size, 1, num_nodes, time_steps)\n",
    "        x_ant = att_nt * x\n",
    "        \n",
    "        # feature - nodes\n",
    "        avg_fn = masked_average_pooling(x, mask, self.pool_dim2, device)\n",
    "        max_fn = masked_max_pooling(x, mask, self.pool_dim2, device)\n",
    "        avg_fn = avg_fn.unsqueeze(1)\n",
    "        max_fn= max_fn.unsqueeze(1)\n",
    "        am_fn = torch.cat((avg_fn, max_fn), dim = 1)\n",
    "        att_fn = self.fn_conv(am_fn) # 输出形状为(batch_size, 1, feature_dim, num_nodes)\n",
    "        \n",
    "        # 将数据形状调整为 (batch_size, time_steps, feature_dim, num_nodes)\n",
    "        data_pfn = x.permute(0, 3, 1, 2)\n",
    "        \n",
    "        # 逐元素相乘\n",
    "        weighted_dfn = att_fn * data_pfn\n",
    "       \n",
    "        # 如果需要恢复原始形状 (batch_size, feature_dim, num_nodes, time_steps)\n",
    "        x_afn = weighted_dfn.permute(0, 2, 3, 1)\n",
    "        \n",
    "        return x_ant + x_afn  # (batch_size, feature_dim, num_nodes, time_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38be0b4f-075c-47da-b506-3cce87470b6f",
   "metadata": {},
   "source": [
    "<span style = 'color:red;font-size:25px'>iTransformer编码器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14049123-b405-4ff5-b071-1cd271f64ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeLU(nn.Module):\n",
    "    def forward(self, input_tensor):\n",
    "        return 0.5 * input_tensor * (1 + torch.tanh(math.sqrt(2 / math.pi) * (input_tensor + 0.044715 * torch.pow(input_tensor, 3))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b300bc6-558d-4846-8443-16ad15240df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddNorm(nn.Module):\n",
    "    \"\"\"残差连接后进行层规范化\"\"\"\n",
    "    def __init__(self, normalized_shape, dropout, **kwargs):\n",
    "        super(AddNorm, self).__init__(**kwargs)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.ln = nn.LayerNorm(normalized_shape)\n",
    "\n",
    "    def forward(self, X, Y):\n",
    "        return self.ln(self.dropout(Y) + X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89eb2e5-8df4-43a2-aaae-58cd92348673",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFFN(nn.Module):\n",
    "    \"\"\"基于位置的前馈网络\"\"\"\n",
    "    def __init__(self, ffn_num_input, ffn_num_hiddens, ffn_num_outputs,\n",
    "                 **kwargs):\n",
    "        super(PositionWiseFFN, self).__init__(**kwargs)\n",
    "        self.dense1 = nn.Linear(ffn_num_input, ffn_num_hiddens)\n",
    "        self.gelu = GeLU()\n",
    "        self.dense2 = nn.Linear(ffn_num_hiddens, ffn_num_outputs)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.dense2(self.gelu(self.dense1(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c9d3c9-327a-4b86-b9f1-662de34ccc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotProductAttention(nn.Module):\n",
    "    \"\"\"缩放点积注意力\"\"\"\n",
    "    def __init__(self, dropout, **kwargs):\n",
    "        super(DotProductAttention, self).__init__(**kwargs)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    # queries的形状：(batch_size，查询的个数，d)\n",
    "    # keys的形状：(batch_size，“键－值”对的个数，d)\n",
    "    # values的形状：(batch_size，“键－值”对的个数，值的维度)\n",
    "    # valid_lens的形状:(batch_size，)或者(batch_size，查询的个数)\n",
    "    def forward(self, queries, keys, values):\n",
    "        d = queries.shape[-1]\n",
    "        # 设置transpose_b=True为了交换keys的最后两个维度\n",
    "        scores = torch.bmm(queries, keys.transpose(1,2)) / math.sqrt(d)\n",
    "        self.attention_weights = nn.functional.softmax(scores, dim = -1)\n",
    "        return torch.bmm(self.dropout(self.attention_weights), values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96064717-da5e-411d-969a-b30537bbcd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transpose_qkv(X, num_heads):\n",
    "    \"\"\"为了多注意力头的并行计算而变换形状\"\"\"\n",
    "    # 输入X的形状:(batch_size, 变量个数, num_hiddens)\n",
    "    # 输出X的形状:(batch_size, 变量个数, num_heads, num_hiddens/num_heads)\n",
    "    X = X.reshape(X.shape[0], X.shape[1], num_heads, -1)\n",
    "\n",
    "    # 输出X的形状:(batch_size, num_heads, 变量个数, num_hiddens/num_heads)\n",
    "    X = X.permute(0, 2, 1, 3)\n",
    "\n",
    "    # 最终输出的形状:(batch_size*num_heads, 变量个数, num_hiddens/num_heads)\n",
    "    return X.reshape(-1, X.shape[2], X.shape[3])\n",
    "\n",
    "def transpose_output(X, num_heads):\n",
    "    \"\"\"逆转transpose_qkv函数的操作\"\"\"\n",
    "    # (batch_size, 变量个数, num_heads, num_hiddens/num_heads)\n",
    "    X = X.reshape(-1, num_heads, X.shape[1], X.shape[2])\n",
    "    X = X.permute(0, 2, 1, 3)\n",
    "    # 最终输出形状(batch_size, 变量个数, num_hiddens)\n",
    "    return X.reshape(X.shape[0], X.shape[1], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725b16e6-7d26-4f2d-a43a-21dd5852d434",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention_1(nn.Module):\n",
    "    \"\"\"多头注意力\"\"\"\n",
    "    def __init__(self, key_size, query_size, value_size, num_hiddens,\n",
    "                 num_heads, dropout, bias=False, **kwargs):\n",
    "        super(MultiHeadAttention_1, self).__init__(**kwargs)\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = DotProductAttention(dropout)\n",
    "        self.W_q = nn.Linear(num_hiddens, num_hiddens, bias=bias)\n",
    "        self.W_k = nn.Linear(num_hiddens, num_hiddens, bias=bias)\n",
    "        self.W_v = nn.Linear(num_hiddens, num_hiddens, bias=bias)\n",
    "        self.W_o = nn.Linear(num_hiddens, num_hiddens, bias=bias)\n",
    "\n",
    "    def forward(self, queries, keys, values):\n",
    "        # queries，keys，values的形状:\n",
    "        # (batch_size，查询或者“键－值”对的个数，num_hiddens)\n",
    "        # valid_lens　的形状:\n",
    "        # (batch_size，)或(batch_size，查询的个数)\n",
    "        # 经过变换后，输出的queries，keys，values　的形状:\n",
    "        # (batch_size*num_heads，查询或者“键－值”对的个数，\n",
    "        # num_hiddens/num_heads)\n",
    "        queries = transpose_qkv(self.W_q(queries), self.num_heads)\n",
    "        keys = transpose_qkv(self.W_k(keys), self.num_heads)\n",
    "        values = transpose_qkv(self.W_v(values), self.num_heads)\n",
    "        # output的形状:(batch_size*num_heads, 变量个数, num_hiddens/num_heads)\n",
    "        output = self.attention(queries, keys, values)\n",
    "\n",
    "        # output_concat的形状:(batch_size, 变量个数, num_hiddens)\n",
    "        output_concat = transpose_output(output, self.num_heads)\n",
    "        return self.W_o(output_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff66d371-935e-4eb6-a8ca-2c031cadb35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock_1(nn.Module):\n",
    "    \"\"\"Transformer编码器块\"\"\"\n",
    "    def __init__(self, key_size, query_size, value_size, num_hiddens, norm_shape,\n",
    "                 ffn_num_input, ffn_num_hiddens, ffn_num_outputs, num_heads, dropout, use_bias=False, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.attention = MultiHeadAttention_1(key_size, query_size, value_size, num_hiddens, num_heads, dropout)\n",
    "        self.addnorm1 = AddNorm(norm_shape, dropout)\n",
    "        self.ffn = PositionWiseFFN(ffn_num_input, ffn_num_hiddens, num_hiddens)\n",
    "        self.addnorm2 = AddNorm(norm_shape, dropout)\n",
    "\n",
    "    def forward(self, X):\n",
    "        Y = self.addnorm1(X, self.attention(X, X, X))\n",
    "        return self.addnorm2(Y, self.ffn(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96d68ae-d827-4d06-9998-fa8275f7931d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class iTransformer_1(nn.Module):\n",
    "    \"\"\"Transformer编码器\"\"\"\n",
    "    def __init__(self, vocab_size, key_size, query_size, value_size,\n",
    "                 num_hiddensT, norm_shape, ffn_num_input, ffn_num_hiddens, ffn_num_outputs,\n",
    "                 num_headsT, num_layersT, pred_len, dropout = 0, use_bias=False, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.vocab_size = vocab_size\n",
    "        self.linear = nn.Linear(num_hiddensT, pred_len)\n",
    "        self.fc = nn.Linear(vocab_size, num_hiddensT)\n",
    "        self.blks = nn.Sequential()\n",
    "        for i in range(num_layersT):\n",
    "            self.blks.add_module(\"block\"+str(i),\n",
    "                EncoderBlock_1(key_size, query_size, value_size, num_hiddensT,\n",
    "                             norm_shape, ffn_num_input, ffn_num_hiddens, ffn_num_outputs,\n",
    "                             num_headsT, dropout, use_bias))\n",
    "    def forward(self, X, *args):\n",
    "        X = self.fc(X)\n",
    "        for i, blk in enumerate(self.blks):\n",
    "            X = blk(X)\n",
    "        return self.linear(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3a58f9-749c-4f07-a291-8366f2ad2b4e",
   "metadata": {},
   "source": [
    "<span style = 'color:red;font-size:25px'>STE模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fdfdfd-38b4-4da1-9212-6ebc98ee4b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class STE_block(nn.Module):\n",
    "    def __init__(self, hidden_dimS, num_heads, embedding_dim2, num_layersl, hidden_sizel, kernel_size, \n",
    "                 hidden_dimT, num_layersT, ffn_num_hiddens, num_headsT, input_len, pred_len):\n",
    "        super(STE_block, self).__init__()\n",
    "       \n",
    "        # 异构图网络\n",
    "        self.S_GAT1 = H_Model(hidden_dimS, num_heads, embedding_dim2)\n",
    "        self.hidden_sizel = hidden_sizel\n",
    "        # 时序-特征注意力机制\n",
    "        self.Lstm1 = LSTMNetwork(hidden_dimS, hidden_sizel, num_layersl)\n",
    "        self.iTsf = iTransformer_1(input_len, input_len, input_len, input_len, hidden_dimT, hidden_dimT, \n",
    "                                   hidden_dimT, ffn_num_hiddens, hidden_dimT, num_headsT, num_layersT, pred_len)\n",
    "        # 坐标注意力\n",
    "        self.att1 = AttentionModule(kernel_size, pool_dim1 = 1, pool_dim2 = 3)\n",
    "        self.fc = nn.Linear(embedding_dim2 * 4, hidden_dimS)\n",
    "        \n",
    "    def forward(self, input_x, data_D, device, masks_x, distances): \n",
    " \n",
    "        batch_size, time_steps, num_nodes, _ = input_x.shape\n",
    "        \n",
    "        x_d, x_s = self.fc(data_D['DYA'].x), self.fc(data_D['STA'].x)\n",
    "        \"节点形状(batch_size * time_steps * num_nodes, feature_dim)\"\n",
    "        x_dictD0 = {'DYA': x_d, 'STA': x_s}\n",
    "        \n",
    "        \"空间特征挖掘\"\n",
    "        X_in = torch.cat((data_D['DYA'].x, data_D['STA'].x), dim = -1).reshape(batch_size, time_steps, num_nodes, -1)\n",
    "        X_in = X_in.permute(0, 2, 3, 1) # 改变形状为(batch_size, num_nodes, feature_dim, time_steps)\n",
    "        \n",
    "        # 异构图训练模块和同构图训练模块 \n",
    "        x_dynamic0, x_static0 = self.S_GAT1(x_dictD0, data_D)  # 返回形状(batch_size * time_steps * 节点数, feature_dim)\n",
    "        \n",
    "        \"坐标注意力计算\"\n",
    "        X_dynamic = x_dictD0['DYA'].reshape(batch_size, time_steps, num_nodes, -1)\n",
    "        X_static = x_dictD0['STA'].reshape(batch_size, time_steps, num_nodes, -1)\n",
    "        X_SD = torch.cat((X_dynamic, X_static), dim = -1).permute(0, 3, 2, 1)\n",
    "        # 坐标注意力\n",
    "        # 输入形状为(batch_size, feature_dim * 2, num_nodes, time_steps)\n",
    "        X_SD0 = self.att1(X_SD, masks_x, device)  # 输出形状为(batch_size, 2*feature_dim, num_nodes, time_steps)\n",
    "        F = X_SD0.shape[1]\n",
    "        X_SD0 = X_SD0.permute(0, 3, 2, 1).reshape(batch_size * time_steps * num_nodes, -1) # 改变形状为(B*T*N, F)   \n",
    "        \n",
    "        \"特征融合\"\n",
    "        X_D0, X_S0 = X_SD0[:, : F // 2], X_SD0[:, F // 2:]\n",
    "        X_D1, X_S1 = x_dynamic0 + X_D0, x_static0 + X_S0\n",
    "        X_D1 = X_D1.reshape(batch_size, time_steps, num_nodes, -1).permute(0, 2, 1, 3).reshape(batch_size * num_nodes, time_steps, -1)\n",
    "        X_S1 = X_S1.reshape(batch_size, time_steps, num_nodes, -1).permute(0, 2, 1, 3).reshape(batch_size * num_nodes, time_steps, -1)\n",
    "        _, h_d, c_d = self.Lstm1(X_D1)\n",
    "        _, h_s, c_s = self.Lstm1(X_S1)\n",
    "        \n",
    "        \"长时序挖掘\"\n",
    "        X_SD1 = torch.cat((data_D['DYA'].x, data_D['STA'].x), dim = -1).reshape(batch_size, time_steps, num_nodes, -1).permute(0, 2, 3, 1)  \n",
    "        X_SD1 = X_SD1.reshape(batch_size * num_nodes, -1, time_steps)                                  \n",
    "       \n",
    "        # 输入形状为(B * N, F, T)\n",
    "        output = self.iTsf(X_SD1) # 输出形状为(batch_size * num_nodes, featrure_dim, time_steps)                                  \n",
    "        \n",
    "        # 返回形状为(batch_size * num_nodes, featrure_dim, time_steps)   \n",
    "        return h_d + h_s, c_d + c_s, output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3dc384-3d9e-465a-ad0a-95ef007d43f5",
   "metadata": {},
   "source": [
    "<span style = 'color:red;font-size:25px'>解码器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45db34a-c3cb-4dfb-89ad-ff0c955e5d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n",
    "        \"\"\"\n",
    "        解码器模型\n",
    "        :param input_dim: 输入特征的维度\n",
    "        :param hidden_dim: 隐藏层维度\n",
    "        :param num_layers: LSTM 层数\n",
    "        :param output_dim: 输出特征的维度\n",
    "        \"\"\"\n",
    "        super(DecoderModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "    def forward(self, target, h, c):\n",
    "        \"\"\"\n",
    "        用于训练的前向传播\n",
    "        :param input_x: 解码器初始输入，形状 (时间步, batch_size, input_dim)\n",
    "        :param hidden: 解码器初始隐藏状态，形状 (1, batch_size, hidden_dim)\n",
    "        :param cell: 解码器初始细胞状态，形状 (1, batch_size, hidden_dim)\n",
    "        :param target: 目标序列，用于训练模式，形状 (target_len, batch_size, input_dim)\n",
    "        :return: 输出序列，形状 (batch_size, target_len, output_dim)\n",
    "        \"\"\"\n",
    "        batch_size = target.size(0)\n",
    "        target_len = target.size(1)\n",
    "        outputs = torch.zeros(batch_size, target_len, self.fc.out_features).to(h.device)\n",
    "        hidden = h\n",
    "        cell = c\n",
    "        # 当前时间步输入\n",
    "        output, (hidden, cell) = self.lstm(target, (hidden.contiguous(), cell.contiguous()))  # LSTM 输出\n",
    "        outputs = self.fc(output)  # 全连接层投影到输出维度\n",
    "        \n",
    "        return outputs   #形状 (batch_size, target_len, output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5eed7c-0816-4b5f-960d-f486045e2365",
   "metadata": {},
   "source": [
    "<span style = 'color:red;font-size:25px'>异构图静态特征嵌入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565bfe4e-56cc-4b88-9a55-443c372d0d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(torch.nn.Module):\n",
    "    def __init__(self, embedding_dim2):\n",
    "        super(Embedding, self).__init__()\n",
    "\n",
    "        # 静态数据编码器层\n",
    "        # 丹麦\n",
    "        self.embedding_layer1 = nn.Embedding(num_embeddings=21, embedding_dim=embedding_dim2)  # 船型\n",
    "        self.embedding_layer2 = nn.Embedding(num_embeddings=65, embedding_dim=embedding_dim2)  # 船长\n",
    "        self.embedding_layer3 = nn.Embedding(num_embeddings=420, embedding_dim=embedding_dim2) # 船宽 \n",
    "        self.embedding_layer4 = nn.Embedding(num_embeddings=15, embedding_dim=embedding_dim2)  # 吃水\n",
    "        \n",
    "        # # 加州\n",
    "        # self.embedding_layer1 = nn.Embedding(num_embeddings=91, embedding_dim=embedding_dim2)  # 船型\n",
    "        # self.embedding_layer2 = nn.Embedding(num_embeddings=61, embedding_dim=embedding_dim2)  # 船长\n",
    "        # self.embedding_layer3 = nn.Embedding(num_embeddings=401, embedding_dim=embedding_dim2) # 船宽 \n",
    "        # self.embedding_layer4 = nn.Embedding(num_embeddings=23, embedding_dim=embedding_dim2)  # 吃水\n",
    "\n",
    "        # # 休斯顿\n",
    "        # self.embedding_layer1 = nn.Embedding(num_embeddings=100, embedding_dim=embedding_dim2)  # 船型\n",
    "        # self.embedding_layer2 = nn.Embedding(num_embeddings=67, embedding_dim=embedding_dim2)   # 船长\n",
    "        # self.embedding_layer3 = nn.Embedding(num_embeddings=365, embedding_dim=embedding_dim2)  # 船宽 \n",
    "        # self.embedding_layer4 = nn.Embedding(num_embeddings=23, embedding_dim=embedding_dim2)   # 吃水\n",
    "        \n",
    "    def forward(self, dataD, device):\n",
    "                \n",
    "        dataD = dataD.to(device)\n",
    "        \n",
    "        self.xd_s = dataD['STA'].x\n",
    "\n",
    "        # 静态属性编码\n",
    "        self.Xd_S1 = self.embedding_layer1(self.xd_s[:, 0].long())  # 船型\n",
    "        self.Xd_S2 = self.embedding_layer2(self.xd_s[:, 1].long())  # 船长\n",
    "        self.Xd_S3 = self.embedding_layer3(self.xd_s[:, 2].long())  # 船宽 \n",
    "        self.Xd_S4 = self.embedding_layer4(self.xd_s[:, 3].long())  # 吃水\n",
    "\n",
    "        self.Xd_S = torch.cat((self.Xd_S1, self.Xd_S2, self.Xd_S3, self.Xd_S4), dim=1)\n",
    "        \n",
    "        # 静态属性获取\n",
    "        dataD['STA'].x = self.Xd_S\n",
    "        \n",
    "        return dataD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49de10d0-09e1-4a28-89ff-b278ed6382be",
   "metadata": {},
   "source": [
    "<span style = 'color:red;font-size:25px'>预测填充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbc27d4-50aa-454b-a013-d98f920b5190",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ipad_out(Y, masks, device):\n",
    "    batch_size, pred_time_steps, max_nodes = masks.shape\n",
    "    _, _, feature_dim = Y.shape\n",
    "    # ========== 简化实现 ==========\n",
    "    # 1) 找到每批次的有效节点\n",
    "    valid_nodes_masks = masks.all(dim=1)  # (batch_size, max_nodes)\n",
    "    valid_nodes_indices = [torch.where(valid_nodes_masks[b])[0] for b in range(batch_size)]  # 每批次有效节点索引列表\n",
    "    \n",
    "    # 2) 初始化全零张量\n",
    "    output = torch.zeros(batch_size, max_nodes, pred_time_steps, feature_dim).to(device)  # (B, max_nodes, T, F)\n",
    "    \n",
    "    # 3) 遍历每批次并填充数据\n",
    "    start_idx = 0\n",
    "    for b in range(batch_size):\n",
    "        valid_indices = valid_nodes_indices[b]  # 当前批次的有效节点索引\n",
    "        num_valid_nodes = len(valid_indices)    # 有效节点数量\n",
    "    \n",
    "        # 提取 Y 中对应的数据\n",
    "        Y_batch = Y[start_idx:start_idx + num_valid_nodes]  # (num_valid_nodes, pred_time_steps, feature_dim)\n",
    "        start_idx += num_valid_nodes\n",
    "    \n",
    "        # 填充到目标张量\n",
    "        output[b, valid_indices, :, :] = Y_batch # shape:(batch_size, max_nodes, time_steps, feature_dim)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e5a605-b995-41a0-bb03-2dd8844fb4ef",
   "metadata": {},
   "source": [
    "<span style = 'color:red;font-size:25px'>时间编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193989a0-13f2-4a80-8e9e-841acc3df315",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_positional_encoding(num_steps, hidden_dim, device):\n",
    "    \"\"\"\n",
    "    生成正弦-余弦位置编码（Positional Encoding）\n",
    "    \n",
    "    参数：\n",
    "    num_steps: 时间步长 (序列长度)\n",
    "    hidden_dim: 特征维度 (需要与隐藏维度匹配)\n",
    "    device: 计算设备（如 'cuda' 或 'cpu'）\n",
    "\n",
    "    返回:\n",
    "    形状为 (num_steps, hidden_dim) 的位置编码张量\n",
    "    \"\"\"\n",
    "    # 创建位置索引矩阵 (num_steps, 1) -> (num_steps,)\n",
    "    position = torch.arange(num_steps, dtype=torch.float, device=device).unsqueeze(1)\n",
    "\n",
    "    # 计算除法因子 (hidden_dim, )\n",
    "    div_term = torch.exp(torch.arange(0, hidden_dim, 2, dtype=torch.float, device=device) * \n",
    "                         -(torch.log(torch.tensor(10000.0, device=device)) / hidden_dim))\n",
    "\n",
    "    # 初始化编码矩阵 (num_steps, hidden_dim)\n",
    "    pe = torch.zeros(num_steps, hidden_dim, device=device)\n",
    "\n",
    "    # 偶数维使用正弦编码，奇数维使用余弦编码\n",
    "    pe[:, 0::2] = torch.sin(position * div_term)  # 偶数索引\n",
    "    pe[:, 1::2] = torch.cos(position * div_term)  # 奇数索引\n",
    "\n",
    "    return pe\n",
    "\n",
    "def add_positional_encoding(static_features, device):\n",
    "    \"\"\"\n",
    "    将位置编码与静态节点特征相结合\n",
    "\n",
    "    参数：\n",
    "    static_features: 输入静态特征张量，形状 (batch_size * 节点数, num_steps, hidden_dim)\n",
    "\n",
    "    返回：\n",
    "    加入位置编码的静态特征，形状不变\n",
    "    \"\"\"\n",
    "    # 获取输入形状\n",
    "    batch_node_size, num_steps, hidden_dim = static_features.shape\n",
    "\n",
    "    # 生成位置编码 (num_steps, hidden_dim)\n",
    "    positional_encoding = generate_positional_encoding(num_steps, hidden_dim, device)\n",
    "\n",
    "    # 通过广播将其添加到静态特征中\n",
    "    static_features_with_encoding = static_features + positional_encoding.unsqueeze(0)\n",
    "\n",
    "    return static_features_with_encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfee957e-4ed7-48ae-bca0-36ec40473a7c",
   "metadata": {},
   "source": [
    "# <span style = 'color:red'>模型主函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6400d9d5-90c3-4c15-b6ba-c17fed6a1987",
   "metadata": {},
   "outputs": [],
   "source": [
    "class H_data(nn.Module):\n",
    "    def __init__(self,input_len,pred_len,input_dimD,hidden_dimD,embedding_dim1,embedding_dim2,hidden_dimS,num_heads,num_layersl,\n",
    "                 hidden_sizel,kernel_size,hidden_dimT,num_layersT,ffn_num_hiddens,num_headsT,num_layersl2, hidden_sizel2):\n",
    "        super(H_data, self).__init__()\n",
    "        self.input_len = input_len\n",
    "        self.pred_len = pred_len\n",
    "        \n",
    "        # 定义模型\n",
    "        self.embed = Embedding(embedding_dim2)\n",
    "        \n",
    "        # 时空模块\n",
    "        self.STE1 = STE_block(hidden_dimS, num_heads, embedding_dim2, num_layersl2, hidden_sizel2, kernel_size, \n",
    "                 hidden_dimT, num_layersT, ffn_num_hiddens, num_headsT, input_len, pred_len) \n",
    "        # 生成\n",
    "        self.lstm = LSTMNetwork(input_dimD, hidden_sizel, num_layersl)\n",
    "        \n",
    "        # 解码器预测输出\n",
    "        self.decoder = DecoderModel(embedding_dim2 * 8, hidden_sizel2, num_layersl2, output_dim = 2)\n",
    "        \n",
    "    def forward(self, input_x, static_X, device, F, S, batch_size, masks_x, distances): \n",
    "        \"\"\"\n",
    "        input_x是一个批次的数据列表，列表长度为batch_size，元素为total_len时间步长的数据形状为(batch_size, 时间步, 节点数, 特征维度)\n",
    "        static_X_list形状为(batch_size, 时间步, 节点数, 特征维度)\n",
    "        F的形状为(batch_size, 节点ID)\n",
    "        S的形状为(batch_size, 时间步, 节点ID)\n",
    "        masks_x的形状为(batch_size, time_steps, num_nodes)\n",
    "        \"\"\"\n",
    "        \n",
    "        batch_size, time_steps, num_nodes, _ = input_x.shape\n",
    "        data_D, batch = HeteroGraphBuilder_batch(input_x, static_X, masks_x, device, distances)\n",
    "        data_D = self.embed(data_D, device)\n",
    "        X_dynamic = data_D['DYA'].x\n",
    "        X_static = data_D['STA'].x\n",
    "    \n",
    "        # # masks_x形状为(batch_size, 时间步, 节点数)\n",
    "        # # input_x形状为(batch_size, 时间步, 节点数, 特征维度)\n",
    "        x_dynamic1, x_static1 = X_dynamic.reshape(batch_size, time_steps, num_nodes, -1), X_static.reshape(batch_size, time_steps, num_nodes, -1)\n",
    "        x_dynamic1, x_static1 = x_dynamic1.permute(0, 2, 1, 3), x_static1.permute(0, 2, 1, 3)  #改变形状为(batch_size, num_nodes, time_steps, feature_dim)\n",
    "        \n",
    "        # 改变形状为(batch_size * 节点数, num_steps, 隐藏维度)\n",
    "        x_dynamic1, x_static1 = x_dynamic1.reshape(-1, time_steps, x_dynamic1.shape[-1]), x_static1.reshape(-1, time_steps, x_static1.shape[-1])\n",
    "        \n",
    "        # 使用LSTM网络捕获时序特征\n",
    "        x_sta1 = add_positional_encoding(x_static1, device)\n",
    "        x_dyn1, _, _ = self.lstm(x_dynamic1)\n",
    "        feature_dim = x_dyn1.shape[-1]\n",
    "        \n",
    "        # 形状改变为(batch_size*time_steps*num_nodes, -1)\n",
    "        x_dyn1 = x_dyn1.reshape(batch_size, num_nodes, time_steps, -1).permute(0, 2, 1, 3).reshape(-1, feature_dim)\n",
    "        x_sta1 = x_sta1.reshape(batch_size, num_nodes, time_steps, -1).permute(0, 2, 1, 3).reshape(-1, feature_dim)\n",
    "        data_D['DYA'].x, data_D['STA'].x = x_dyn1, x_sta1\n",
    "\n",
    "        # \n",
    "        h_D, c_D, X_din = self.STE1(input_x, data_D, device, masks_x, distances) # 输出形状为(B * N, F, T)\n",
    "        X_din = X_din.permute(0, 2, 1)\n",
    "\n",
    "        # 解码输出\n",
    "        Y_h = self.decoder(X_din, h_D, c_D)   # Y_h的形状为(batch_size * 节点数, 时间步, 隐藏特征维度)\n",
    "        Y_hat = Y_h.reshape(batch_size, num_nodes, self.pred_len, -1) # 改变形状为(B, N, T, F)    \n",
    "       \n",
    "        \"结束\"\n",
    "        # # 扩展 mask 的形状到 (batch_size, time_steps, num_nodes, 1)\n",
    "        masks_out = masks_x[:, :self.pred_len, :].to(device)\n",
    "\n",
    "        return Y_hat, masks_out          # Y_hat shape:(batch_size, max_nodes, time_steps, feature_dim),\n",
    "                                                         # masks_out shape: (batch_size, time_steps, max_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce4bc82-999d-4bcb-94c9-50394cb2ef54",
   "metadata": {},
   "source": [
    "<span style = 'color:red; font-size:25px'>实时显示训练结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1e514a-efe2-4261-b263-4f5a87082954",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Animator:  #@save\n",
    "    \"\"\"在动画中绘制数据\"\"\"\n",
    "    def __init__(self, xlabel=None, ylabel=None, legend=None, xlim=None,\n",
    "                 ylim=None, xscale='linear', yscale='linear',\n",
    "                 fmts=('-', 'm--', 'g-.', 'r:'), nrows=1, ncols=1,\n",
    "                 figsize=(3.5, 2.5)):\n",
    "        # 增量地绘制多条线\n",
    "        if legend is None:\n",
    "            legend = []\n",
    "        d2l.use_svg_display()\n",
    "        self.fig, self.axes = d2l.plt.subplots(nrows, ncols, figsize=figsize)\n",
    "        if nrows * ncols == 1:\n",
    "            self.axes = [self.axes, ]\n",
    "        # 使用lambda函数捕获参数\n",
    "        self.config_axes = lambda: d2l.set_axes(\n",
    "            self.axes[0], xlabel, ylabel, xlim, ylim, xscale, yscale, legend)\n",
    "        self.X, self.Y, self.fmts = None, None, fmts\n",
    "\n",
    "    def add(self, x, y):\n",
    "        # 向图表中添加多个数据点\n",
    "        if not hasattr(y, \"__len__\"):\n",
    "            y = [y]\n",
    "        n = len(y)\n",
    "        if not hasattr(x, \"__len__\"):\n",
    "            x = [x] * n\n",
    "        if not self.X:\n",
    "            self.X = [[] for _ in range(n)]\n",
    "        if not self.Y:\n",
    "            self.Y = [[] for _ in range(n)]\n",
    "        for i, (a, b) in enumerate(zip(x, y)):\n",
    "            if a is not None and b is not None:\n",
    "                self.X[i].append(a)\n",
    "                self.Y[i].append(b)\n",
    "        self.axes[0].cla()\n",
    "        for x, y, fmt in zip(self.X, self.Y, self.fmts):\n",
    "            self.axes[0].plot(x, y, fmt)\n",
    "        self.config_axes()\n",
    "        display.display(self.fig)\n",
    "        display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a4be3e-6f06-47e5-ab22-8951e80354fa",
   "metadata": {},
   "source": [
    "# <span style = 'color:red;font-size:25px'>填充数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d759817-a76b-43f2-94ed-f34107ee8cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_outputy(output_Y):\n",
    "    \"\"\"\n",
    "    对形状为 (batch_size, 时间步, 节点数, 特征) 的不规则列表进行填充，并生成掩码。\n",
    "    \n",
    "    :param output_Y: 一个列表，每个元素形状为 (时间步, 节点数, 特征)\n",
    "    :return: \n",
    "        - padded_output: 填充后的张量，形状为 (batch_size, 时间步, max_nodes, 特征)\n",
    "        - masks: 填充掩码，形状为 (batch_size, 时间步, max_nodes)\n",
    "    \"\"\"\n",
    "    # 如果 output_Y 是空的，或者包含空数组，直接返回空张量\n",
    "    if not output_Y or any(len(y) == 0 for y in output_Y):\n",
    "        # print(\"output_Y 为空或包含空数组，返回空结果\")\n",
    "        return torch.empty(0), torch.empty(0)\n",
    "    \n",
    "    # 转换为 NumPy 数组并检查形状有效性\n",
    "    output_Y = [np.array(y) for y in output_Y if len(y) > 0]\n",
    "    max_nodes = max(y.shape[1] for y in output_Y)\n",
    "    feature_dim = output_Y[0].shape[2]\n",
    "    max_time_steps = max(y.shape[0] for y in output_Y)\n",
    "    batch_size = len(output_Y)\n",
    "\n",
    "    # 初始化填充张量和掩码\n",
    "    padded_output = torch.zeros((batch_size, max_time_steps, max_nodes, feature_dim), dtype=torch.float32)\n",
    "    masks = torch.zeros((batch_size, max_time_steps, max_nodes), dtype=torch.float32)\n",
    "\n",
    "    # 填充数据和生成掩码\n",
    "    for i, batch in enumerate(output_Y):\n",
    "        t, n, f = batch.shape\n",
    "        padded_output[i, :t, :n, :] = torch.tensor(batch, dtype=torch.float32)\n",
    "        masks[i, :t, :n] = 1.0\n",
    "\n",
    "    return padded_output, masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfc88c5-3617-4f3e-a336-f671f701dd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_output(output_Y):\n",
    "    \"\"\"\n",
    "    对形状为 (batch_size, [时间步的列表], 节点数, 特征) 的不规则输入数据进行填充，并生成掩码。\n",
    "    \n",
    "    :param output_Y: 一个嵌套列表，包含 NumPy 数组或张量，每个元素是 (节点数, 特征) 的数组\n",
    "    :return: \n",
    "        - padded_output: 填充后的张量，形状为 (batch_size, max_time_steps, max_nodes, feature_dim)\n",
    "        - masks: 填充掩码，形状为 (batch_size, max_time_steps, max_nodes)\n",
    "    \"\"\"\n",
    "    batch_size = len(output_Y)\n",
    "\n",
    "    # 获取每个 batch 中时间步的数量\n",
    "    time_steps_list = [len(batch) for batch in output_Y]\n",
    "    max_time_steps = max(time_steps_list)  # 最大时间步数\n",
    "\n",
    "    # 找到最大节点数和特征维度\n",
    "    max_nodes = max([array.shape[0] for batch in output_Y for array in batch])\n",
    "    feature_dim = max([array.shape[1] for batch in output_Y for array in batch])\n",
    "\n",
    "    # 初始化填充后的张量和掩码\n",
    "    padded_output = torch.zeros((batch_size, max_time_steps, max_nodes, feature_dim), dtype=torch.float32)\n",
    "    masks = torch.zeros((batch_size, max_time_steps, max_nodes), dtype=torch.float32)\n",
    "    \n",
    "    # 填充数据并生成掩码\n",
    "    for i, batch in enumerate(output_Y):\n",
    "        for t, array in enumerate(batch):  # 遍历时间步\n",
    "            num_nodes, num_features = array.shape\n",
    "            padded_output[i, t, :num_nodes, :num_features] = torch.tensor(array, dtype=torch.float32)\n",
    "            masks[i, t, :num_nodes] = 1.0  # 有效数据位置为 1.0\n",
    "    \n",
    "    return padded_output, masks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc45add3-54c2-4c68-8455-b566ea4ce349",
   "metadata": {},
   "source": [
    "<span style = 'color:red;font-size:25px'>训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be15807-1254-4c1d-bdd9-2990dc938e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ade(predictions, ground_truth, mask):\n",
    "    \"\"\"\n",
    "    计算ADE值\n",
    "    :param predictions: 预测张量，形状为 (batch_size, pred_time, num_nodes, feature_dim)\n",
    "    :param ground_truth: 真实值张量，形状为 (batch_size, pred_time, num_nodes, feature_dim)\n",
    "    :param mask: 遮掩矩阵，形状为 (batch_size, pred_time, num_nodes, feature_dim)\n",
    "    :return: ADE值和有效节点数\n",
    "    \"\"\"\n",
    "    # 计算 L2 范数（欧氏距离）：每个时间步、每个节点上的预测误差\n",
    "    displacement_error = torch.sqrt(torch.sum((predictions - ground_truth) ** 2, dim=-1))  # (batch_size, pred_time, num_nodes)\n",
    "    \n",
    "    # 将 mask 的最后一个维度降维以匹配 displacement_error\n",
    "    mask_reduced = mask.any(dim=-1).float()  # (batch_size, pred_time, num_nodes)\n",
    "    \n",
    "    # 将填充部分的误差置为 0\n",
    "    masked_error = displacement_error * mask_reduced  # (batch_size, pred_time, num_nodes)\n",
    "    \n",
    "    # 累计误差总和和有效节点数\n",
    "    total_error = masked_error.sum()  # 总误差\n",
    "    valid_count = mask_reduced.sum()  # 有效节点总数\n",
    "    \n",
    "    return total_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163bcf1b-2896-4030-96dc-a363f46af4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize_columns(normalized_data, max_values, min_values):\n",
    "    \"\"\"\n",
    "    逆归一化函数，支持 NumPy 数组和 PyTorch 张量。\n",
    "\n",
    "    参数:\n",
    "    normalized_data (numpy array or torch tensor): 归一化后的数据\n",
    "    max_values (list or numpy array or torch tensor): 每列的最大值\n",
    "    min_values (list or numpy array or torch tensor): 每列的最小值\n",
    "\n",
    "    返回:\n",
    "    逆归一化后的数据 (与输入类型相同)\n",
    "    \"\"\"\n",
    "    # 如果数据是 PyTorch Tensor，确保 max_values 和 min_values 也是 Tensor\n",
    "    if isinstance(normalized_data, torch.Tensor):\n",
    "        max_values = torch.tensor(max_values, dtype=normalized_data.dtype, device=normalized_data.device)\n",
    "        min_values = torch.tensor(min_values, dtype=normalized_data.dtype, device=normalized_data.device)\n",
    "        return normalized_data * (max_values - min_values) + min_values\n",
    "    \n",
    "    # 否则，按 NumPy 方式计算\n",
    "    max_values = np.array(max_values)\n",
    "    min_values = np.array(min_values)\n",
    "    return normalized_data * (max_values - min_values) + min_values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c324e04b-8c96-42f9-a27c-249cf0bf1fa1",
   "metadata": {},
   "source": [
    "<span style = 'color:red;font-size:25px'>模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f224fbaa-3c81-444c-9916-d530e06ed0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lunwen(net, lr, epochs, input_len, pred_len, file_path, file_vpath, file_pathS,\n",
    "                 weight_decay, max_values, min_values, batch_size, hidden_dimT):\n",
    "    \"\"\"训练序列到序列模型：精简版\"\"\"\n",
    "\n",
    "    def xavier_init_weights(m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "    # 初始化权重\n",
    "    net.apply(xavier_init_weights)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "    torch.cuda.init()\n",
    "    # device = 'cpu'\n",
    "    \n",
    "    net.to(device)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)  # 每10个epoch学习率减半\n",
    "    loss = nn.L1Loss()\n",
    "    \n",
    "    # 读取并转换静态数据\n",
    "    dataS = extract_mmsi_features(file_pathS)\n",
    "    dataS = transform_data(dataS)\n",
    "    \n",
    "    net.train()\n",
    "    animator = Animator(xlabel='epoch', ylabel='loss', yscale='log', xlim=[0, epochs],\n",
    "                        legend=['train', 'valid'])\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        timer = d2l.Timer()\n",
    "        metric = d2l.Accumulator(2)         # 记录训练中 L1Loss\n",
    "        metric_mae = d2l.Accumulator(2)    # 记录训练中 MAE\n",
    "        metric_ade = d2l.Accumulator(2) # 记录验证集 MAE\n",
    "        metric_mvalid = d2l.Accumulator(2) # 记录验证集 MAE\n",
    "        metric_made = d2l.Accumulator(2) # 记录验证集 ADE\n",
    "        timer.start()\n",
    "        \n",
    "        # ------------------ 训练 ------------------\n",
    "        for slice_y in slice_data_generator(file_path, input_len, pred_len, batch_size):\n",
    "            \n",
    "            # 梯度清零\n",
    "            optimizer.zero_grad()\n",
    "            if len(slice_y) != batch_size:\n",
    "                break\n",
    "            \n",
    "            input_X, F, output_Y, S, _, input_x_all, Static_result_all = process_data(\n",
    "                slice_y, input_len, pred_len, dataS\n",
    "            )\n",
    "            if not input_x_all or all(len(batch) == 0 for batch in input_x_all):\n",
    "                break\n",
    "\n",
    "            In_x, masks_x = pad_output(input_x_all)\n",
    "            In_xr = In_x.reshape(-1, In_x.shape[3]).to(device)\n",
    "            masks_xr = masks_x.reshape(-1).bool()\n",
    "            np.seterr(divide='ignore')\n",
    "            distances = (1 / haversine_distances(In_xr)).to(device)\n",
    "            Out_Y, masks_Y0 = pad_outputy(output_Y)\n",
    "            if Out_Y.shape[0] == 0:\n",
    "                break\n",
    "            In_x1, Out_Y1 = In_x[:, :, :, :2].to(device), Out_Y[:, :, :, :2].to(device)\n",
    "            n_x = torch.cat((In_x1[:, 0].unsqueeze(1), In_x1[:, :-1]), dim=1)\n",
    "            n_y = torch.cat((Out_Y1[:, 0].unsqueeze(1), Out_Y1[:, :-1]), dim=1)\n",
    "            masks_y = masks_Y0.to(device)\n",
    "            in_x = normalize_datat(In_x, max_values, min_values)\n",
    "            Out_Y = normalize_datat(Out_Y, max_values, min_values)\n",
    "            sta_x, _ = pad_output(Static_result_all)\n",
    "            Y_h, _ = net(in_x, sta_x, device, F, S, batch_size, masks_x, distances)  \n",
    "            masks_Y = masks_y.bool().unsqueeze(-1).expand_as(Out_Y1)\n",
    "            masked_Y = Out_Y * masks_Y\n",
    "            masked_Y1 = Out_Y1 * masks_Y\n",
    "            masked_Y_hat = Y_hat * masks_Y\n",
    "            l = loss(masked_Y, masked_Y_hat)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                masked_Y_ht = denormalize_data(masked_Y_hat, max_values, min_values)\n",
    "                masked_Y_ht = masked_Y_ht * masks_Y\n",
    "                ADE_ = calculate_ade(masked_Y_ht, masked_Y1, masks_Y)\n",
    "                mae = torch.abs(masked_Y_ht - masked_Y1) * masks_Y\n",
    "                valid_count = masks_Y.sum().item()\n",
    "                metric.add(l.sum(), valid_count)\n",
    "                metric_mae.add(mae.sum(), valid_count) \n",
    "                metric_ade.add(ADE_.sum(), valid_count // 2) \n",
    "            l.sum().backward()\n",
    "            optimizer.step()\n",
    "        scheduler.step()  \n",
    "        \n",
    "        # ------------------ 验证 ------------------\n",
    "        with torch.no_grad():\n",
    "            for slice_vy in slice_data_generator(file_vpath, input_len, pred_len, batch_size):\n",
    "                if len(slice_vy) != batch_size:\n",
    "                    break\n",
    "\n",
    "                input_vX, v_F, output_vY, v_S, _, input_vx_all, Static_vresult_all = process_data(\n",
    "                    slice_vy, input_len, pred_len, dataS\n",
    "                )\n",
    "                if not input_vx_all or all(len(batch) == 0 for batch in input_vx_all):\n",
    "                    break\n",
    "    \n",
    "                In_vx, masks_vx = pad_output(input_vx_all)\n",
    "                In_vxr = In_vx.reshape(-1, In_vx.shape[3]).to(device)\n",
    "                masks_vxr = masks_vx.reshape(-1).bool()\n",
    "                np.seterr(divide='ignore')\n",
    "                distances_v = (1 / haversine_distances(In_vxr)).to(device)\n",
    "                \n",
    "                Out_vY, masks_vY0 = pad_outputy(output_vY) \n",
    "                if Out_vY.shape[0] == 0:\n",
    "                    break\n",
    "                \n",
    "                In_vx1, Out_vY1 = In_vx[:, :, :, :2].to(device), Out_vY[:, :, :, :2].to(device)\n",
    "                n_vx = torch.cat((In_vx1[:, 0].unsqueeze(1), In_vx1[:, :-1]), dim=1)\n",
    "                n_vy = torch.cat((Out_vY1[:, 0].unsqueeze(1), Out_vY1[:, :-1]), dim=1)\n",
    "                \n",
    "                masks_vy = masks_vY0.to(device)\n",
    "                in_vx = normalize_datat(In_vx, max_values, min_values)\n",
    "                sta_vx, _ = pad_output(Static_vresult_all)\n",
    "    \n",
    "                vY_h, _ = net(in_vx, sta_vx, device, v_F, v_S, batch_size, masks_vx, distances_v)  \n",
    "                vY_hat = denormalize_data(vY_h, max_values, min_values)\n",
    "    \n",
    "                masks_vY = masks_vy.bool().unsqueeze(-1).expand_as(Out_vY1)\n",
    "                masked_vY = Out_vY1 * masks_vY\n",
    "                masked_vY_hat = vY_hat * masks_vY\n",
    "                vADE_ = calculate_ade(masked_vY_hat, masked_vY, masks_vY)\n",
    "                mae_v = torch.abs(masked_vY_hat - masked_vY) * masks_vY\n",
    "                valid_vcount = masks_vY.sum().item()\n",
    "                metric_mvalid.add(mae_v.sum(), valid_vcount)\n",
    "                metric_made.add(vADE_.sum(), valid_vcount // 2)\n",
    "        if (epoch + 1) % 1 == 0:\n",
    "                animator.add(epoch + 1, ((metric_mae[0]/metric_mae[1], metric_mvalid[0]/metric_mvalid[1])))\n",
    "        print(f'epoch{epoch+1}train_loss:{metric_mae[0]/metric_mae[1]}')\n",
    "        print(f'epoch{epoch+1}valid_loss:{metric_mvalid[0]/metric_mvalid[1]}')\n",
    "        print(f'epoch{epoch+1}train_loss:{metric_ade[0]/metric_ade[1]}')\n",
    "        print(f'epoch{epoch+1}valid_loss:{metric_made[0]/metric_made[1]}')\n",
    "        print(f\"Epoch {epoch + 1}, Time: {timer.stop():.1f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0574a2dc-536c-4d44-9424-3895e57355d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383c48e7-064c-426f-8e24-a37b5a448c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_len = 48  # 输入时间长度\n",
    "pred_len = 24   # 预测时间长度\n",
    "num_heads = 2  # 图神经注意力头数\n",
    "embedding_dim1 = 2  # 船型嵌入特征维度\n",
    "embedding_dim2 = 4  # 其他静态特征嵌入维度\n",
    "hidden_dimS = 32   # 异构图特征隐藏维度\n",
    "hidden_dimT = 128 # TCN特征隐藏维度\n",
    "num_layersS = 2   # 异构图层数\n",
    "num_layersT = 5   # TCN1层数\n",
    "input_dimD = 5  # 异构图神经动态特征输入维度\n",
    "hidden_dimD = 12\n",
    "input_dimS = output_dimS = hidden_sizel = embedding_dim2 * 4  # 异构图神经静态输入数据 \n",
    "num_layersl = 2   # LSTM层数\n",
    "num_layersl2 = 4\n",
    "hidden_sizel2 = 128\n",
    "kernel_size = 3  # 卷积核尺寸\n",
    "ffn_num_hiddens = 256\n",
    "num_headsT = 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42378cf-58ed-4b7f-8ee5-29a99bdf84b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ea5d04-d817-4b9f-80f8-bf188ecdd802",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = H_data(input_len,pred_len,input_dimD,hidden_dimD,embedding_dim1,embedding_dim2,hidden_dimS,num_heads,num_layersl,\n",
    "                 hidden_sizel,kernel_size,hidden_dimT,num_layersT,ffn_num_hiddens,num_headsT,num_layersl2, hidden_sizel2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8843d7f9-0fb5-4d96-a090-283f4021f345",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ddb78d-ebfd-40d1-aaec-a987fcb563f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path =  # 训练数据集地址\n",
    "file_vpath = # 验证数据集地址\n",
    "file_tpath = # 测试数据集地址\n",
    "file_pathS = # 静态数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ca1c38-3926-4822-969d-37075e307b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_values = [57.1976249957228, 8.411638137361614, 29.770000000000003, 359.9, 180.0]    # 最大值列表\n",
    "min_values = [54.959007898554255, 6.297554604493042, 0.5, 0.0, 0.0]                     # 最小值列表\n",
    "weight_decay = 0   # 正则化\n",
    "lr = 0.0001        # 学习率\n",
    "epochs = 100       # 迭代次数\n",
    "batch_size = 2     # 窗口数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc164902-493b-43d1-97f8-14797d610738",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lunwen(net, lr, epochs, input_len, pred_len, file_path, file_vpath, file_pathS, weight_decay, max_values, min_values, batch_size, hidden_dimT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b81eea-b30d-41ee-8bc2-be9f9f1a95eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1259e0da-fb0b-403b-b8bf-d21468985261",
   "metadata": {},
   "source": [
    "<span style = 'color:red;font-size:25px'>模型测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700db4b3-7e22-41a3-9844-e60837496f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_lunwen(net, input_len, pred_len, file_tpath, file_pathS, \n",
    "                max_values, min_values, batch_size):\n",
    "    \"\"\"训练序列到序列模型：精简版 + 吞吐量(轨迹/秒)统计\"\"\"\n",
    "\n",
    "    # 设备选择与初始化\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "        torch.cuda.init()\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    \n",
    "    net.to(device)\n",
    "\n",
    "    # 读取并转换静态数据\n",
    "    dataS = extract_mmsi_features(file_pathS)\n",
    "    dataS = transform_data(dataS)\n",
    "    \n",
    "    net.eval()\n",
    "\n",
    "    timer = d2l.Timer()\n",
    "    metric_tmse = d2l.Accumulator(2)\n",
    "    metric_trmse = d2l.Accumulator(2)\n",
    "    metric_tmae = d2l.Accumulator(2)\n",
    "    metric_tade = d2l.Accumulator(2)\n",
    "\n",
    "    total_pred_time = 0.0     # 总推理时间（秒）\n",
    "    total_trajectories = 0.0  # 总轨迹数量（按你的口径：valid_tcount/24/2）\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for slice_ty in slice_data_generator(file_tpath, input_len, pred_len, batch_size):\n",
    "            if len(slice_ty) != batch_size:\n",
    "                break\n",
    "\n",
    "            input_tX, t_F, output_tY, t_S, _, input_tx_all, Static_tresult_all = process_data(\n",
    "                slice_ty, input_len, pred_len, dataS\n",
    "            )\n",
    "            if not input_tx_all or all(len(batch) == 0 for batch in input_tx_all):\n",
    "                break\n",
    "\n",
    "            In_tx, masks_tx = pad_output(input_tx_all)\n",
    "            In_txr = In_tx.reshape(-1, In_tx.shape[3])\n",
    "            masks_txr = masks_tx.reshape(-1).bool()\n",
    "            np.seterr(divide='ignore')\n",
    "            distances_t = (1 / haversine_distances(In_txr)).to(device)\n",
    "            \n",
    "            Out_tY, masks_tY0 = pad_outputy(output_tY) \n",
    "            if Out_tY.shape[0] == 0:\n",
    "                break\n",
    "            \n",
    "            In_tx1, Out_tY1 = In_tx[:, :, :, :2].to(device), Out_tY[:, :, :, :2].to(device)\n",
    "            n_tx = torch.cat((In_tx1[:, 0].unsqueeze(1), In_tx1[:, :-1]), dim=1)\n",
    "            n_ty = torch.cat((Out_tY1[:, 0].unsqueeze(1), Out_tY1[:, :-1]), dim=1)\n",
    "            \n",
    "            masks_ty = masks_tY0.to(device)\n",
    "            in_tx = normalize_datat(In_tx, max_values, min_values)\n",
    "            sta_tx, _ = pad_output(Static_tresult_all)\n",
    "\n",
    "            # === 记录推理时间（GPU 同步确保计时准确）===\n",
    "            if device.type == \"cuda\":\n",
    "                torch.cuda.synchronize()\n",
    "            start_time = time.time()\n",
    "\n",
    "            tY_h, _, att_nt, att_fn = net(in_tx, sta_tx, device, t_F, t_S, batch_size, masks_tx, distances_t)\n",
    "\n",
    "            if device.type == \"cuda\":\n",
    "                torch.cuda.synchronize()\n",
    "            end_time = time.time()\n",
    "            # =========================================\n",
    "\n",
    "            tY_hat = denormalize_data(tY_h, max_values, min_values)\n",
    "            masks_tY = masks_ty.bool().unsqueeze(-1).expand_as(Out_tY1)\n",
    "            masked_tY = Out_tY1 * masks_tY\n",
    "            masked_tY_hat = tY_hat * masks_tY\n",
    "\n",
    "            tADE_ = calculate_ade(masked_tY_hat, masked_tY, masks_tY)\n",
    "            mae_t = torch.abs(masked_tY_hat - masked_tY) * masks_tY\n",
    "            mse_t = calculate_mse(masked_tY, masked_tY_hat)\n",
    "            rmse_t = torch.sqrt(mse_t)\n",
    "            valid_tcount = masks_tY.sum().item()\n",
    "\n",
    "            # ====== 推理耗时与轨迹统计 =====\n",
    "            total_pred_time += (end_time - start_time)\n",
    "            # 维持你原本的换算口径（可按需要自行修改）\n",
    "            total_trajectories += valid_tcount / 24.0 / 2.0\n",
    "            # =================================\n",
    "\n",
    "            metric_tmse.add(mse_t.sum(), valid_tcount)\n",
    "            metric_trmse.add(rmse_t.sum(), valid_tcount)\n",
    "            metric_tmae.add(mae_t.sum(), valid_tcount)\n",
    "            metric_tade.add(tADE_.sum(), valid_tcount / 2.0)\n",
    "\n",
    "    print(f'test_mae:  {metric_tmae[0]/metric_tmae[1]:.6f}')\n",
    "    print(f'test_ade:  {metric_tade[0]/metric_tade[1]:.6f}m')\n",
    "    print(f'test_mse:  {metric_tmse[0]/metric_tmse[1]:.6f}')\n",
    "    print(f'test_rmse: {torch.sqrt(torch.tensor(metric_tmse[0]/metric_tmse[1])):.6f}')\n",
    "\n",
    "    print(f\"total_pred_time(s): {total_pred_time:.6f}\")\n",
    "    print(f\"total_trajectories: {total_trajectories:.6f}\")\n",
    "\n",
    "    # 平均每条轨迹推理时间\n",
    "    if total_trajectories > 0:\n",
    "        avg_time_per_traj = total_pred_time / total_trajectories\n",
    "        print(f'Average inference time per trajectory: {avg_time_per_traj:.6f} seconds')\n",
    "\n",
    "        # 轨迹/秒吞吐量\n",
    "        traj_per_sec = total_trajectories / total_pred_time if total_pred_time > 0 else float(\"inf\")\n",
    "        print(f'Throughput (trajectories/sec): {traj_per_sec:.6f}')\n",
    "    else:\n",
    "        print(\"No valid trajectory batches processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bee578e-219a-4321-bbd4-eecc2978f37b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d88344-47e7-4268-b617-70d5cbf3af85",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lunwen(net, input_len, pred_len, file_tpath, file_pathS, max_values, min_values, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8142ba58-64f3-43a7-b307-856cd742e126",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e923d0-8add-4df0-a015-993c679a5698",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032b446d-419b-4479-945b-a0c5f52344ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7086e4b5-e65e-4dcf-95fc-ef1fbe226cd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170d329b-9479-410c-9ead-0cb8ea92c38d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
